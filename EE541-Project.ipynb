{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T19:58:19.588742Z","iopub.status.busy":"2023-05-07T19:58:19.588360Z","iopub.status.idle":"2023-05-07T19:58:19.595502Z","shell.execute_reply":"2023-05-07T19:58:19.594374Z","shell.execute_reply.started":"2023-05-07T19:58:19.588705Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from torch.utils.data import DataLoader, random_split\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","import torch.nn.functional as F\n","import torchsummary\n","import copy\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T15:37:53.799010Z","iopub.status.busy":"2023-05-07T15:37:53.797884Z","iopub.status.idle":"2023-05-07T15:39:33.574697Z","shell.execute_reply":"2023-05-07T15:39:33.573470Z","shell.execute_reply.started":"2023-05-07T15:37:53.798977Z"},"trusted":true},"outputs":[],"source":["train_transforms = transforms.Compose([\n","    transforms.RandomRotation(10),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.Resize((200, 200)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","test_transforms = transforms.Compose([\n","    transforms.Resize((200, 200)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_data = ImageFolder('/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/', transform=train_transforms)\n","test_dataset = ImageFolder('/kaggle/input/asl-alphabet-modified-test/asl_alphabet_test/asl_alphabet_test/', transform=test_transforms)\n","unseen_test_dataset = ImageFolder('/kaggle/input/asl-alphabet-test/', transform=test_transforms)\n","\n","train_size = int(0.8 * len(train_data))\n","val_size = int(0.2 * len(train_data))\n","train_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","unseen_test_loader = DataLoader(unseen_test_dataset, batch_size=64, shuffle=False)\n","\n","print(\"Train Dataset Size: \",len(train_dataset))\n","print(\"Validation Dataset Size: \",len(val_dataset))\n","print(\"Test Dataset Size: \",len(test_dataset))\n","print(\"Unseen Test Dataset Size: \",len(unseen_test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load a pre-trained DenseNet model\n","ResNet_model = models.resnet50(pretrained=True)\n","\n","# Freeze layers\n","for param in ResNet_model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the classifier\n","num_features = ResNet_model.fc.in_features\n","ResNet_model.fc = nn.Linear(num_features, 29)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(ResNet_model.fc.parameters(), lr=0.001)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","ResNet_model = ResNet_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    ResNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = ResNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    ResNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = ResNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Specify the file path on your Google Drive\n","file_path = '/kaggle/working/frozen_resnet_model.pth'\n","\n","# Save the model\n","torch.save(ResNet_model.state_dict(), file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, param in ResNet_model.named_parameters():\n","    if 'layer1' in name:\n","        param.requires_grad = True\n","        \n","    if 'layer2' in name:\n","        param.requires_grad = False\n","    \n","    if 'layer3' in name:\n","        param.requires_grad = False\n","    \n","    if 'layer4' in name:\n","        param.requires_grad = False\n","optimizer = optim.Adam(ResNet_model.parameters(), lr=0.0001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    ResNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = ResNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    ResNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = ResNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, param in ResNet_model.named_parameters():\n","    if 'layer1' in name:\n","        param.requires_grad = True\n","        \n","    if 'layer2' in name:\n","        param.requires_grad = True\n","    \n","    if 'layer3' in name:\n","        param.requires_grad = False\n","    \n","    if 'layer4' in name:\n","        param.requires_grad = False\n","optimizer = optim.Adam(ResNet_model.parameters(), lr=0.00001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    ResNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = ResNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    ResNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = ResNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, param in ResNet_model.named_parameters():\n","    if 'layer1' in name:\n","        param.requires_grad = True\n","        \n","    if 'layer2' in name:\n","        param.requires_grad = True\n","    \n","    if 'layer3' in name:\n","        param.requires_grad = True\n","    \n","    if 'layer4' in name:\n","        param.requires_grad = False\n","optimizer = optim.Adam(ResNet_model.parameters(), lr=0.000001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    ResNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = ResNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    ResNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = ResNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, param in ResNet_model.named_parameters():\n","    if 'layer1' in name:\n","        param.requires_grad = True\n","        \n","    if 'layer2' in name:\n","        param.requires_grad = True\n","    \n","    if 'layer3' in name:\n","        param.requires_grad = True\n","    \n","    if 'layer4' in name:\n","        param.requires_grad = True\n","optimizer = optim.Adam(ResNet_model.parameters(), lr=0.00001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    ResNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = ResNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    ResNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = ResNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (ResNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ResNet_model.eval()\n","with torch.no_grad():\n","    test_total = 0\n","    test_correct = 0\n","    y_true = []\n","    y_pred = []\n","    for images, labels in unseen_test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = ResNet_model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","    test_acc = (test_correct / test_total)*100\n","    print('Test Accuracy: {:.2f}%'.format(test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ResNet_model.eval()\n","with torch.no_grad():\n","    test_total = 0\n","    test_correct = 0\n","    y_true = []\n","    y_pred = []\n","    for images, labels in unseen_test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = ResNet_model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","    test_acc = (test_correct / test_total)*100\n","    print('Test Accuracy for unseen data: {:.2f}%'.format(test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Specify the file path on your Google Drive\n","file_path = '/kaggle/working/tuned_resnet_model.pth'\n","\n","# Save the model\n","torch.save(ResNet_model.state_dict(), file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ResNet_model_copy = copy.deepcopy(ResNet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ResNet_model_summary = torchsummary.summary(ResNet_model, input_size=(3, 200, 200))\n","print(ResNet_model_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T15:39:33.577780Z","iopub.status.busy":"2023-05-07T15:39:33.577010Z","iopub.status.idle":"2023-05-07T15:39:37.091741Z","shell.execute_reply":"2023-05-07T15:39:37.090709Z","shell.execute_reply.started":"2023-05-07T15:39:33.577734Z"},"trusted":true},"outputs":[],"source":["# Load a pre-trained DenseNet model\n","DenseNet_model = models.densenet121(pretrained=True)\n","\n","# Freeze layers\n","for param in DenseNet_model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the classifier\n","num_features = DenseNet_model.classifier.in_features\n","DenseNet_model.classifier = nn.Linear(num_features, 29)\n","\n","# Define loss function and optimizer\n","optimizer = optim.Adam(DenseNet_model.classifier.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","DenseNet_model = DenseNet_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T15:39:37.093918Z","iopub.status.busy":"2023-05-07T15:39:37.093499Z","iopub.status.idle":"2023-05-07T16:20:43.850609Z","shell.execute_reply":"2023-05-07T16:20:43.849514Z","shell.execute_reply.started":"2023-05-07T15:39:37.093876Z"},"trusted":true},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    DenseNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = DenseNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    DenseNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = DenseNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T16:20:43.854503Z","iopub.status.busy":"2023-05-07T16:20:43.853756Z","iopub.status.idle":"2023-05-07T16:20:43.958517Z","shell.execute_reply":"2023-05-07T16:20:43.957473Z","shell.execute_reply.started":"2023-05-07T16:20:43.854461Z"},"trusted":true},"outputs":[],"source":["# Specify the file path on your Google Drive\n","file_path = '/kaggle/working/frozen_densenet_model.pth'\n","\n","# Save the model\n","torch.save(DenseNet_model.state_dict(), file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, param in DenseNet_model.named_parameters():\n","    if 'transition3' in name:\n","        param.requires_grad = True\n","        \n","    if 'denseblock4' in name:\n","        param.requires_grad = False\n","    \n","    if 'norm5' in name:\n","        param.requires_grad = False\n","        \n","optimizer = optim.Adam(DenseNet_model.parameters(), lr=0.0001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    DenseNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = DenseNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    DenseNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = DenseNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T16:20:43.960575Z","iopub.status.busy":"2023-05-07T16:20:43.960174Z","iopub.status.idle":"2023-05-07T16:20:43.972080Z","shell.execute_reply":"2023-05-07T16:20:43.970955Z","shell.execute_reply.started":"2023-05-07T16:20:43.960518Z"},"trusted":true},"outputs":[],"source":["for name, param in DenseNet_model.named_parameters():\n","    if 'transition3' in name:\n","        param.requires_grad = True\n","        \n","    if 'denseblock4' in name:\n","        param.requires_grad = True\n","    \n","    if 'norm5' in name:\n","        param.requires_grad = False\n","        \n","optimizer = optim.Adam(DenseNet_model.parameters(), lr=0.00001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T16:20:43.974655Z","iopub.status.busy":"2023-05-07T16:20:43.973996Z","iopub.status.idle":"2023-05-07T16:52:32.873650Z","shell.execute_reply":"2023-05-07T16:52:32.872474Z","shell.execute_reply.started":"2023-05-07T16:20:43.974611Z"},"trusted":true},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    DenseNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = DenseNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    DenseNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = DenseNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, param in DenseNet_model.named_parameters():\n","    if 'transition3' in name:\n","        param.requires_grad = True\n","        \n","    if 'denseblock4' in name:\n","        param.requires_grad = True\n","    \n","    if 'norm5' in name:\n","        param.requires_grad = True\n","        \n","optimizer = optim.Adam(DenseNet_model.parameters(), lr=0.000001)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 5\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","    running_loss = 0.0\n","    DenseNet_model.train()\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = DenseNet_model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = (train_correct / train_total)*100\n","    train_losses.append(train_loss)\n","    train_accs.append(train_acc)\n","\n","    # Evaluate the model on the validation set\n","    DenseNet_model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = DenseNet_model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total += labels.size(0)\n","            val_correct += (predicted == labels).sum().item()\n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = (val_correct / val_total)*100\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","    print(f'Epoch {epoch+1} Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.2f}%')\n","\n","plt.plot(range(1, num_epochs+1), train_losses, label='train')\n","plt.plot(range(1, num_epochs+1), val_losses, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title(f'Loss vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(range(1, num_epochs+1), train_accs, label='train')\n","plt.plot(range(1, num_epochs+1), val_accs, label='val')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title(f'Accuracy vs Epoch (DenseNet)')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T16:52:32.876206Z","iopub.status.busy":"2023-05-07T16:52:32.875133Z","iopub.status.idle":"2023-05-07T16:52:32.976765Z","shell.execute_reply":"2023-05-07T16:52:32.975725Z","shell.execute_reply.started":"2023-05-07T16:52:32.876166Z"},"trusted":true},"outputs":[],"source":["# Specify the file path on your Google Drive\n","file_path = '/kaggle/working/tuned_densenet_model.pth'\n","\n","# Save the model\n","torch.save(DenseNet_model.state_dict(), file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T18:21:09.207165Z","iopub.status.busy":"2023-05-07T18:21:09.206446Z","iopub.status.idle":"2023-05-07T18:21:09.296280Z","shell.execute_reply":"2023-05-07T18:21:09.295264Z","shell.execute_reply.started":"2023-05-07T18:21:09.207127Z"},"trusted":true},"outputs":[],"source":["DenseNet_model_copy = copy.deepcopy(DenseNet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-07T18:47:21.134094Z","iopub.status.busy":"2023-05-07T18:47:21.133726Z","iopub.status.idle":"2023-05-07T18:47:21.852982Z","shell.execute_reply":"2023-05-07T18:47:21.851535Z","shell.execute_reply.started":"2023-05-07T18:47:21.134059Z"},"trusted":true},"outputs":[],"source":["DenseNet_model.eval()\n","with torch.no_grad():\n","    test_total = 0\n","    test_correct = 0\n","    y_true = []\n","    y_pred = []\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = DenseNet_model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","    test_acc = (test_correct / test_total)*100\n","    print('Test Accuracy: {:.2f}%'.format(test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DenseNet_model.eval()\n","with torch.no_grad():\n","    test_total = 0\n","    test_correct = 0\n","    y_true = []\n","    y_pred = []\n","    for images, labels in unseen_test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = DenseNet_model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","    test_acc = (test_correct / test_total)*100\n","    print('Test Accuracy for unseen data: {:.2f}%'.format(test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DenseNet_model_summary = torchsummary.summary(DenseNet_model, input_size=(3, 200, 200))\n","print(DenseNet_model_summary)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
